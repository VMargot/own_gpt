{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev my own GPT for stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "with open(r'../assets/contes.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  441596\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LA BARBE BLEUE.\n",
      "\n",
      "Il était une fois un homme qui avait de belles maisons à la ville et à la campagne, de la vaisselle d'or et d'argent, des meubles en broderie et des carrosses tout dorés. Mais, par malheur, cet homme avait la barbe bleue; cela le rendait si\n",
      "\n",
      "laid et si terrible, qu'il n'était femme ni fille qui ne s'enfuît devant lui.\n",
      "\n",
      "Une de ses voisines, dame de qualité, avait deux filles parfaitement belles. Il lui en demanda une en mariage, en lui laissant le choix de celle qu'elle voulait lui donner. Elles n'en voulaient point toutes deux, et se le renvoyaient l'une à l'autre, ne pouvant se résoudre à prendre un homme qui eût la barbe bleue. Ce qui les dégoûta encore, c'est qu'il avait déjà épousé plusieurs femmes, et qu'on ne savait ce que ces femmes étaient devenues.\n",
      "\n",
      "La Barbe Bleue, pour faire connaissance, les mena, avec leur mère et trois ou quatre de leurs meilleures amies, et quelques jeunes gens du voisinage, à une de ses maisons de campagne, où on demeura huit jours entie\n"
     ]
    }
   ],
   "source": [
    "# look the first 1000 characters\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"'(),-.0123456789:;?ABCDEFGHIJLMNOPQRSTUVXYZabcdefghijlmnopqrstuvxyz«»ÇÉÊàâçèéêëîïôùûœ—\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "# get all unique characters that occur\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can use SentencePiece from Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 47, 57, 66, 65, 7, 1, 65, 66, 1, 67, 47, 64, 1, 48, 55, 51, 59, 1, 22]\n",
      "Salut, tu vas bien ?\n"
     ]
    }
   ],
   "source": [
    "# Charater to integers\n",
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]  # encoding part\n",
    "decode = lambda l: ''.join([itos[i] for i in l])  # decoding part\n",
    "\n",
    "print(encode('Salut, tu vas bien ?'))\n",
    "print(decode(encode('Salut, tu vas bien ?')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the package tiktoken from OpenIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17691, 332, 11, 9964, 44496, 14707, 949]\n",
      "Salut, tu vas bien ?\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "# enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "print(enc.encode(\"Salut, tu vas bien ?\"))\n",
    "print(enc.decode(enc.encode(\"Salut, tu vas bien ?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([441596]) torch.int64\n",
      "tensor([33, 23,  1, 24, 23, 39, 24, 27,  1, 24, 33, 27, 42, 27,  9,  0,  0, 31,\n",
      "        57,  1, 80, 65, 47, 55, 65,  1, 66, 59, 51,  1, 52, 60, 55, 64,  1, 66,\n",
      "        59,  1, 54, 60, 58, 58, 51,  1, 62, 66, 55,  1, 47, 67, 47, 55, 65,  1,\n",
      "        50, 51,  1, 48, 51, 57, 57, 51, 64,  1, 58, 47, 55, 64, 60, 59, 64,  1,\n",
      "        76,  1, 57, 47,  1, 67, 55, 57, 57, 51,  1, 51, 65,  1, 76,  1, 57, 47,\n",
      "         1, 49, 47, 58, 61, 47, 53, 59, 51,  7,  1, 50, 51,  1, 57, 47,  1, 67,\n",
      "        47, 55, 64, 64, 51, 57, 57, 51,  1, 50,  4, 60, 63,  1, 51, 65,  1, 50,\n",
      "         4, 47, 63, 53, 51, 59, 65,  7,  1, 50, 51, 64,  1, 58, 51, 66, 48, 57,\n",
      "        51, 64,  1, 51, 59,  1, 48, 63, 60, 50, 51, 63, 55, 51,  1, 51, 65,  1,\n",
      "        50, 51, 64,  1, 49, 47, 63, 63, 60, 64, 64, 51, 64,  1, 65, 60, 66, 65,\n",
      "         1, 50, 60, 63, 80, 64,  9,  1, 34, 47, 55, 64,  7,  1, 61, 47, 63,  1,\n",
      "        58, 47, 57, 54, 51, 66, 63,  7,  1, 49, 51, 65,  1, 54, 60, 58, 58, 51,\n",
      "         1, 47, 67, 47, 55, 65,  1, 57, 47,  1, 48, 47, 63, 48, 51,  1, 48, 57,\n",
      "        51, 66, 51, 21,  1, 49, 51, 57, 47,  1, 57, 51,  1, 63, 51, 59, 50, 47,\n",
      "        55, 65,  1, 64, 55,  0,  0, 57, 47, 55, 50,  1, 51, 65,  1, 64, 55,  1,\n",
      "        65, 51, 63, 63, 55, 48, 57, 51,  7,  1, 62, 66,  4, 55, 57,  1, 59,  4,\n",
      "        80, 65, 47, 55, 65,  1, 52, 51, 58, 58, 51,  1, 59, 55,  1, 52, 55, 57,\n",
      "        57, 51,  1, 62, 66, 55,  1, 59, 51,  1, 64,  4, 51, 59, 52, 66, 83, 65,\n",
      "         1, 50, 51, 67, 47, 59, 65,  1, 57, 66, 55,  9,  0,  0, 42, 59, 51,  1,\n",
      "        50, 51,  1, 64, 51, 64,  1, 67, 60, 55, 64, 55, 59, 51, 64,  7,  1, 50,\n",
      "        47, 58, 51,  1, 50, 51,  1, 62, 66, 47, 57, 55, 65, 80,  7,  1, 47, 67,\n",
      "        47, 55, 65,  1, 50, 51, 66, 68,  1, 52, 55, 57, 57, 51, 64,  1, 61, 47,\n",
      "        63, 52, 47, 55, 65, 51, 58, 51, 59, 65,  1, 48, 51, 57, 57, 51, 64,  9,\n",
      "         1, 31, 57,  1, 57, 66, 55,  1, 51, 59,  1, 50, 51, 58, 47, 59, 50, 47,\n",
      "         1, 66, 59, 51,  1, 51, 59,  1, 58, 47, 63, 55, 47, 53, 51,  7,  1, 51,\n",
      "        59,  1, 57, 66, 55,  1, 57, 47, 55, 64, 64, 47, 59, 65,  1, 57, 51,  1,\n",
      "        49, 54, 60, 55, 68,  1, 50, 51,  1, 49, 51, 57, 57, 51,  1, 62, 66,  4,\n",
      "        51, 57, 57, 51,  1, 67, 60, 66, 57, 47, 55, 65,  1, 57, 66, 55,  1, 50,\n",
      "        60, 59, 59, 51, 63,  9,  1, 27, 57, 57, 51, 64,  1, 59,  4, 51, 59,  1,\n",
      "        67, 60, 66, 57, 47, 55, 51, 59, 65,  1, 61, 60, 55, 59, 65,  1, 65, 60,\n",
      "        66, 65, 51, 64,  1, 50, 51, 66, 68,  7,  1, 51, 65,  1, 64, 51,  1, 57,\n",
      "        51,  1, 63, 51, 59, 67, 60, 69, 47, 55, 51, 59, 65,  1, 57,  4, 66, 59,\n",
      "        51,  1, 76,  1, 57,  4, 47, 66, 65, 63, 51,  7,  1, 59, 51,  1, 61, 60,\n",
      "        66, 67, 47, 59, 65,  1, 64, 51,  1, 63, 80, 64, 60, 66, 50, 63, 51,  1,\n",
      "        76,  1, 61, 63, 51, 59, 50, 63, 51,  1, 66, 59,  1, 54, 60, 58, 58, 51,\n",
      "         1, 62, 66, 55,  1, 51, 87, 65,  1, 57, 47,  1, 48, 47, 63, 48, 51,  1,\n",
      "        48, 57, 51, 66, 51,  9,  1, 25, 51,  1, 62, 66, 55,  1, 57, 51, 64,  1,\n",
      "        50, 80, 53, 60, 87, 65, 47,  1, 51, 59, 49, 60, 63, 51,  7,  1, 49,  4,\n",
      "        51, 64, 65,  1, 62, 66,  4, 55, 57,  1, 47, 67, 47, 55, 65,  1, 50, 80,\n",
      "        56, 76,  1, 80, 61, 60, 66, 64, 80,  1, 61, 57, 66, 64, 55, 51, 66, 63,\n",
      "        64,  1, 52, 51, 58, 58, 51, 64,  7,  1, 51, 65,  1, 62, 66,  4, 60, 59,\n",
      "         1, 59, 51,  1, 64, 47, 67, 47, 55, 65,  1, 49, 51,  1, 62, 66, 51,  1,\n",
      "        49, 51, 64,  1, 52, 51, 58, 58, 51, 64,  1, 80, 65, 47, 55, 51, 59, 65,\n",
      "         1, 50, 51, 67, 51, 59, 66, 51, 64,  9,  0,  0, 33, 47,  1, 24, 47, 63,\n",
      "        48, 51,  1, 24, 57, 51, 66, 51,  7,  1, 61, 60, 66, 63,  1, 52, 47, 55,\n",
      "        63, 51,  1, 49, 60, 59, 59, 47, 55, 64, 64, 47, 59, 49, 51,  7,  1, 57,\n",
      "        51, 64,  1, 58, 51, 59, 47,  7,  1, 47, 67, 51, 49,  1, 57, 51, 66, 63,\n",
      "         1, 58, 79, 63, 51,  1, 51, 65,  1, 65, 63, 60, 55, 64,  1, 60, 66,  1,\n",
      "        62, 66, 47, 65, 63, 51,  1, 50, 51,  1, 57, 51, 66, 63, 64,  1, 58, 51,\n",
      "        55, 57, 57, 51, 66, 63, 51, 64,  1, 47, 58, 55, 51, 64,  7,  1, 51, 65,\n",
      "         1, 62, 66, 51, 57, 62, 66, 51, 64,  1, 56, 51, 66, 59, 51, 64,  1, 53,\n",
      "        51, 59, 64,  1, 50, 66,  1, 67, 60, 55, 64, 55, 59, 47, 53, 51,  7,  1,\n",
      "        76,  1, 66, 59, 51,  1, 50, 51,  1, 64, 51, 64,  1, 58, 47, 55, 64, 60,\n",
      "        59, 64,  1, 50, 51,  1, 49, 47, 58, 61, 47, 53, 59, 51,  7,  1, 60, 86,\n",
      "         1, 60, 59,  1, 50, 51, 58, 51, 66, 63, 47,  1, 54, 66, 55, 65,  1, 56,\n",
      "        60, 66, 63, 64,  1, 51, 59, 65, 55, 51])\n"
     ]
    }
   ],
   "source": [
    "# We encode the entire text dataset and store it into torch.Tensor\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in train and test\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([33, 23,  1, 24, 23, 39, 24, 27,  1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8  #This is the size of the context\n",
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the input is tensor([33]) the target is: 23\n",
      "When the input is tensor([33, 23]) the target is: 1\n",
      "When the input is tensor([33, 23,  1]) the target is: 24\n",
      "When the input is tensor([33, 23,  1, 24]) the target is: 23\n",
      "When the input is tensor([33, 23,  1, 24, 23]) the target is: 39\n",
      "When the input is tensor([33, 23,  1, 24, 23, 39]) the target is: 24\n",
      "When the input is tensor([33, 23,  1, 24, 23, 39, 24]) the target is: 27\n",
      "When the input is tensor([33, 23,  1, 24, 23, 39, 24, 27]) the target is: 1\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]\n",
    "for t in range(block_size):\n",
    "    context = x[: t + 1]\n",
    "    target = y[t]\n",
    "    print(f\"When the input is {context} the target is: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs :\n",
      "torch.Size([4, 8])\n",
      "tensor([[55, 65,  1, 66, 59,  1, 61, 51],\n",
      "        [66, 55,  1, 47, 57, 57, 79, 63],\n",
      "        [ 9,  0,  0, 31, 57,  1, 48, 47],\n",
      "        [55, 57, 57, 51,  1, 57, 51,  1]])\n",
      "\n",
      "Tragets :\n",
      "torch.Size([4, 8])\n",
      "tensor([[65,  1, 66, 59,  1, 61, 51, 66],\n",
      "        [55,  1, 47, 57, 57, 79, 63, 51],\n",
      "        [ 0,  0, 31, 57,  1, 48, 47, 55],\n",
      "        [57, 57, 51,  1, 57, 51,  1, 58]])\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size = 4  # how many independent sequences will we process in //\n",
    "block_size = 8  # what ia the maximum context length for predictions\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    x = torch.stack([data[i: i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1: i + block_size + 1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('Inputs :')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('')\n",
    "print('Tragets :')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the input is tensor([55]) the target is: 65\n",
      "When the input is tensor([55, 65]) the target is: 1\n",
      "When the input is tensor([55, 65,  1]) the target is: 66\n",
      "When the input is tensor([55, 65,  1, 66]) the target is: 59\n",
      "When the input is tensor([55, 65,  1, 66, 59]) the target is: 1\n",
      "When the input is tensor([55, 65,  1, 66, 59,  1]) the target is: 61\n",
      "When the input is tensor([55, 65,  1, 66, 59,  1, 61]) the target is: 51\n",
      "When the input is tensor([55, 65,  1, 66, 59,  1, 61, 51]) the target is: 66\n",
      "When the input is tensor([66]) the target is: 55\n",
      "When the input is tensor([66, 55]) the target is: 1\n",
      "When the input is tensor([66, 55,  1]) the target is: 47\n",
      "When the input is tensor([66, 55,  1, 47]) the target is: 57\n",
      "When the input is tensor([66, 55,  1, 47, 57]) the target is: 57\n",
      "When the input is tensor([66, 55,  1, 47, 57, 57]) the target is: 79\n",
      "When the input is tensor([66, 55,  1, 47, 57, 57, 79]) the target is: 63\n",
      "When the input is tensor([66, 55,  1, 47, 57, 57, 79, 63]) the target is: 51\n",
      "When the input is tensor([9]) the target is: 0\n",
      "When the input is tensor([9, 0]) the target is: 0\n",
      "When the input is tensor([9, 0, 0]) the target is: 31\n",
      "When the input is tensor([ 9,  0,  0, 31]) the target is: 57\n",
      "When the input is tensor([ 9,  0,  0, 31, 57]) the target is: 1\n",
      "When the input is tensor([ 9,  0,  0, 31, 57,  1]) the target is: 48\n",
      "When the input is tensor([ 9,  0,  0, 31, 57,  1, 48]) the target is: 47\n",
      "When the input is tensor([ 9,  0,  0, 31, 57,  1, 48, 47]) the target is: 55\n",
      "When the input is tensor([55]) the target is: 57\n",
      "When the input is tensor([55, 57]) the target is: 57\n",
      "When the input is tensor([55, 57, 57]) the target is: 51\n",
      "When the input is tensor([55, 57, 57, 51]) the target is: 1\n",
      "When the input is tensor([55, 57, 57, 51,  1]) the target is: 57\n",
      "When the input is tensor([55, 57, 57, 51,  1, 57]) the target is: 51\n",
      "When the input is tensor([55, 57, 57, 51,  1, 57, 51]) the target is: 1\n",
      "When the input is tensor([55, 57, 57, 51,  1, 57, 51,  1]) the target is: 58\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t + 1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"When the input is {context} the target is: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size) -> None:\n",
    "        super().__init__()\n",
    "        # Each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B, T) tensor of intergers\n",
    "        logits = self.token_embedding_table(idx)  # (B, T, C)\n",
    "        # B => Number of batch\n",
    "        # T => The size of the context\n",
    "        # C => Number od Channel, i.e. the size of the vocabulary\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # For the cross_entropy the channel C must be the second one\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only in the last time step\n",
    "            logits = logits[:, -1, :]\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=1)  # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T + 1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross entropy return a loss for a random choose around $-ln(1/vocab\\_size)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 90])\n",
      "tensor(5.3363, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lLxETYvCpnfô2aM4èîyRTn8EôAîFzpxvz1s»Fi—2n?Z9;Êee-ErLLeO7'çèDuPoGâ5dôâEdi8,tëcxVbbÉî7Bi3ù;UQ8cÉMe-àv5\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(list(m.generate(idx, max_new_tokens=100)[0].numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of a pytroch optimization object\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [04:33<00:00, 365.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3640780448913574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in tqdm(range(100000)):\n",
    "\n",
    "    # sample batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()  # get the gradients for all parameters\n",
    "    optimizer.step()  # uptdate parameters\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vent, elhéchava chai se qui-grenoit, irone mogainvoù va fe mis det blouintant, blaievavœu'one n rempées r »\n",
      "n a qu'ét.\n",
      "\n",
      "Ile ail ceurou'all de, de chet. ju aitre des ce pamitt drsill ne ss mpon eunene deinseueai ces'a-it cr, e. plluvorre ablletos te je r. mons allemoite à à porerifuintaît-met fi na pe t qunsan paime e t-à an d oitôt, let, vou'ai (cesin Pep. qui!\n",
      "El, lle, d Puaissureto- ut de let t \n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(list(m.generate(idx, max_new_tokens=400)[0].numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid communication bewteen past and the \"future\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first use a very poor meethod to aggregate previous information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want x[b, t] = mean_{i<=t} x_{b, i}\n",
    "# version 1: uggly way\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, : t + 1] # (t, C)\n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3565, -0.1091],\n",
       "        [ 1.5039,  1.5870],\n",
       "        [ 0.8381,  0.2145],\n",
       "        [-1.5449,  1.0934],\n",
       "        [ 1.0445, -1.5426],\n",
       "        [ 1.1026,  0.5029],\n",
       "        [-0.5149, -0.2694],\n",
       "        [-0.7648, -0.9041]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3565, -0.1091],\n",
       "        [ 0.9302,  0.7390],\n",
       "        [ 0.8995,  0.5641],\n",
       "        [ 0.2884,  0.6965],\n",
       "        [ 0.4396,  0.2486],\n",
       "        [ 0.5501,  0.2910],\n",
       "        [ 0.3980,  0.2110],\n",
       "        [ 0.2526,  0.0716]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use a better way to aggregate information using // calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "----\n",
      "b =  tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "----\n",
      "c =  tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b  # matrix multiplication\n",
    "print(\"a = \", a)\n",
    "print('----')\n",
    "print(\"b = \", b)\n",
    "print('----')\n",
    "print(\"c = \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: use @\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei /= wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x  # (T, T) * (B, T, C) --> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros(T, T)\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
