{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev my own GPT for stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "with open(r'../assets/contes.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  441596\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LA BARBE BLEUE.\n",
      "\n",
      "Il était une fois un homme qui avait de belles maisons à la ville et à la campagne, de la vaisselle d'or et d'argent, des meubles en broderie et des carrosses tout dorés. Mais, par malheur, cet homme avait la barbe bleue; cela le rendait si\n",
      "\n",
      "laid et si terrible, qu'il n'était femme ni fille qui ne s'enfuît devant lui.\n",
      "\n",
      "Une de ses voisines, dame de qualité, avait deux filles parfaitement belles. Il lui en demanda une en mariage, en lui laissant le choix de celle qu'elle voulait lui donner. Elles n'en voulaient point toutes deux, et se le renvoyaient l'une à l'autre, ne pouvant se résoudre à prendre un homme qui eût la barbe bleue. Ce qui les dégoûta encore, c'est qu'il avait déjà épousé plusieurs femmes, et qu'on ne savait ce que ces femmes étaient devenues.\n",
      "\n",
      "La Barbe Bleue, pour faire connaissance, les mena, avec leur mère et trois ou quatre de leurs meilleures amies, et quelques jeunes gens du voisinage, à une de ses maisons de campagne, où on demeura huit jours entie\n"
     ]
    }
   ],
   "source": [
    "# look the first 1000 characters\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"'(),-.0123456789:;?ABCDEFGHIJLMNOPQRSTUVXYZabcdefghijlmnopqrstuvxyz«»ÇÉÊàâçèéêëîïôùûœ—\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "# get all unique characters that occur\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can use SentencePiece from Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 47, 57, 66, 65, 7, 1, 65, 66, 1, 67, 47, 64, 1, 48, 55, 51, 59, 1, 22]\n",
      "Salut, tu vas bien ?\n"
     ]
    }
   ],
   "source": [
    "# Charater to integers\n",
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]  # encoding part\n",
    "decode = lambda l: ''.join([itos[i] for i in l])  # decoding part\n",
    "\n",
    "print(encode('Salut, tu vas bien ?'))\n",
    "print(decode(encode('Salut, tu vas bien ?')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the package tiktoken from OpenIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17691, 332, 11, 9964, 44496, 14707, 949]\n",
      "Salut, tu vas bien ?\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "# enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "print(enc.encode(\"Salut, tu vas bien ?\"))\n",
    "print(enc.decode(enc.encode(\"Salut, tu vas bien ?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([441596]) torch.int64\n",
      "tensor([33, 23,  1, 24, 23, 39, 24, 27,  1, 24, 33, 27, 42, 27,  9,  0,  0, 31,\n",
      "        57,  1, 80, 65, 47, 55, 65,  1, 66, 59, 51,  1, 52, 60, 55, 64,  1, 66,\n",
      "        59,  1, 54, 60, 58, 58, 51,  1, 62, 66, 55,  1, 47, 67, 47, 55, 65,  1,\n",
      "        50, 51,  1, 48, 51, 57, 57, 51, 64,  1, 58, 47, 55, 64, 60, 59, 64,  1,\n",
      "        76,  1, 57, 47,  1, 67, 55, 57, 57, 51,  1, 51, 65,  1, 76,  1, 57, 47,\n",
      "         1, 49, 47, 58, 61, 47, 53, 59, 51,  7,  1, 50, 51,  1, 57, 47,  1, 67,\n",
      "        47, 55, 64, 64, 51, 57, 57, 51,  1, 50,  4, 60, 63,  1, 51, 65,  1, 50,\n",
      "         4, 47, 63, 53, 51, 59, 65,  7,  1, 50, 51, 64,  1, 58, 51, 66, 48, 57,\n",
      "        51, 64,  1, 51, 59,  1, 48, 63, 60, 50, 51, 63, 55, 51,  1, 51, 65,  1,\n",
      "        50, 51, 64,  1, 49, 47, 63, 63, 60, 64, 64, 51, 64,  1, 65, 60, 66, 65,\n",
      "         1, 50, 60, 63, 80, 64,  9,  1, 34, 47, 55, 64,  7,  1, 61, 47, 63,  1,\n",
      "        58, 47, 57, 54, 51, 66, 63,  7,  1, 49, 51, 65,  1, 54, 60, 58, 58, 51,\n",
      "         1, 47, 67, 47, 55, 65,  1, 57, 47,  1, 48, 47, 63, 48, 51,  1, 48, 57,\n",
      "        51, 66, 51, 21,  1, 49, 51, 57, 47,  1, 57, 51,  1, 63, 51, 59, 50, 47,\n",
      "        55, 65,  1, 64, 55,  0,  0, 57, 47, 55, 50,  1, 51, 65,  1, 64, 55,  1,\n",
      "        65, 51, 63, 63, 55, 48, 57, 51,  7,  1, 62, 66,  4, 55, 57,  1, 59,  4,\n",
      "        80, 65, 47, 55, 65,  1, 52, 51, 58, 58, 51,  1, 59, 55,  1, 52, 55, 57,\n",
      "        57, 51,  1, 62, 66, 55,  1, 59, 51,  1, 64,  4, 51, 59, 52, 66, 83, 65,\n",
      "         1, 50, 51, 67, 47, 59, 65,  1, 57, 66, 55,  9,  0,  0, 42, 59, 51,  1,\n",
      "        50, 51,  1, 64, 51, 64,  1, 67, 60, 55, 64, 55, 59, 51, 64,  7,  1, 50,\n",
      "        47, 58, 51,  1, 50, 51,  1, 62, 66, 47, 57, 55, 65, 80,  7,  1, 47, 67,\n",
      "        47, 55, 65,  1, 50, 51, 66, 68,  1, 52, 55, 57, 57, 51, 64,  1, 61, 47,\n",
      "        63, 52, 47, 55, 65, 51, 58, 51, 59, 65,  1, 48, 51, 57, 57, 51, 64,  9,\n",
      "         1, 31, 57,  1, 57, 66, 55,  1, 51, 59,  1, 50, 51, 58, 47, 59, 50, 47,\n",
      "         1, 66, 59, 51,  1, 51, 59,  1, 58, 47, 63, 55, 47, 53, 51,  7,  1, 51,\n",
      "        59,  1, 57, 66, 55,  1, 57, 47, 55, 64, 64, 47, 59, 65,  1, 57, 51,  1,\n",
      "        49, 54, 60, 55, 68,  1, 50, 51,  1, 49, 51, 57, 57, 51,  1, 62, 66,  4,\n",
      "        51, 57, 57, 51,  1, 67, 60, 66, 57, 47, 55, 65,  1, 57, 66, 55,  1, 50,\n",
      "        60, 59, 59, 51, 63,  9,  1, 27, 57, 57, 51, 64,  1, 59,  4, 51, 59,  1,\n",
      "        67, 60, 66, 57, 47, 55, 51, 59, 65,  1, 61, 60, 55, 59, 65,  1, 65, 60,\n",
      "        66, 65, 51, 64,  1, 50, 51, 66, 68,  7,  1, 51, 65,  1, 64, 51,  1, 57,\n",
      "        51,  1, 63, 51, 59, 67, 60, 69, 47, 55, 51, 59, 65,  1, 57,  4, 66, 59,\n",
      "        51,  1, 76,  1, 57,  4, 47, 66, 65, 63, 51,  7,  1, 59, 51,  1, 61, 60,\n",
      "        66, 67, 47, 59, 65,  1, 64, 51,  1, 63, 80, 64, 60, 66, 50, 63, 51,  1,\n",
      "        76,  1, 61, 63, 51, 59, 50, 63, 51,  1, 66, 59,  1, 54, 60, 58, 58, 51,\n",
      "         1, 62, 66, 55,  1, 51, 87, 65,  1, 57, 47,  1, 48, 47, 63, 48, 51,  1,\n",
      "        48, 57, 51, 66, 51,  9,  1, 25, 51,  1, 62, 66, 55,  1, 57, 51, 64,  1,\n",
      "        50, 80, 53, 60, 87, 65, 47,  1, 51, 59, 49, 60, 63, 51,  7,  1, 49,  4,\n",
      "        51, 64, 65,  1, 62, 66,  4, 55, 57,  1, 47, 67, 47, 55, 65,  1, 50, 80,\n",
      "        56, 76,  1, 80, 61, 60, 66, 64, 80,  1, 61, 57, 66, 64, 55, 51, 66, 63,\n",
      "        64,  1, 52, 51, 58, 58, 51, 64,  7,  1, 51, 65,  1, 62, 66,  4, 60, 59,\n",
      "         1, 59, 51,  1, 64, 47, 67, 47, 55, 65,  1, 49, 51,  1, 62, 66, 51,  1,\n",
      "        49, 51, 64,  1, 52, 51, 58, 58, 51, 64,  1, 80, 65, 47, 55, 51, 59, 65,\n",
      "         1, 50, 51, 67, 51, 59, 66, 51, 64,  9,  0,  0, 33, 47,  1, 24, 47, 63,\n",
      "        48, 51,  1, 24, 57, 51, 66, 51,  7,  1, 61, 60, 66, 63,  1, 52, 47, 55,\n",
      "        63, 51,  1, 49, 60, 59, 59, 47, 55, 64, 64, 47, 59, 49, 51,  7,  1, 57,\n",
      "        51, 64,  1, 58, 51, 59, 47,  7,  1, 47, 67, 51, 49,  1, 57, 51, 66, 63,\n",
      "         1, 58, 79, 63, 51,  1, 51, 65,  1, 65, 63, 60, 55, 64,  1, 60, 66,  1,\n",
      "        62, 66, 47, 65, 63, 51,  1, 50, 51,  1, 57, 51, 66, 63, 64,  1, 58, 51,\n",
      "        55, 57, 57, 51, 66, 63, 51, 64,  1, 47, 58, 55, 51, 64,  7,  1, 51, 65,\n",
      "         1, 62, 66, 51, 57, 62, 66, 51, 64,  1, 56, 51, 66, 59, 51, 64,  1, 53,\n",
      "        51, 59, 64,  1, 50, 66,  1, 67, 60, 55, 64, 55, 59, 47, 53, 51,  7,  1,\n",
      "        76,  1, 66, 59, 51,  1, 50, 51,  1, 64, 51, 64,  1, 58, 47, 55, 64, 60,\n",
      "        59, 64,  1, 50, 51,  1, 49, 47, 58, 61, 47, 53, 59, 51,  7,  1, 60, 86,\n",
      "         1, 60, 59,  1, 50, 51, 58, 51, 66, 63, 47,  1, 54, 66, 55, 65,  1, 56,\n",
      "        60, 66, 63, 64,  1, 51, 59, 65, 55, 51])\n"
     ]
    }
   ],
   "source": [
    "# We encode the entire text dataset and store it into torch.Tensor\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in train and test\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([33, 23,  1, 24, 23, 39, 24, 27,  1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8  #This is the size of the context\n",
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the input is tensor([33]) the target is: 23\n",
      "When the input is tensor([33, 23]) the target is: 1\n",
      "When the input is tensor([33, 23,  1]) the target is: 24\n",
      "When the input is tensor([33, 23,  1, 24]) the target is: 23\n",
      "When the input is tensor([33, 23,  1, 24, 23]) the target is: 39\n",
      "When the input is tensor([33, 23,  1, 24, 23, 39]) the target is: 24\n",
      "When the input is tensor([33, 23,  1, 24, 23, 39, 24]) the target is: 27\n",
      "When the input is tensor([33, 23,  1, 24, 23, 39, 24, 27]) the target is: 1\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]\n",
    "for t in range(block_size):\n",
    "    context = x[: t + 1]\n",
    "    target = y[t]\n",
    "    print(f\"When the input is {context} the target is: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs :\n",
      "torch.Size([4, 8])\n",
      "tensor([[55, 65,  1, 66, 59,  1, 61, 51],\n",
      "        [66, 55,  1, 47, 57, 57, 79, 63],\n",
      "        [ 9,  0,  0, 31, 57,  1, 48, 47],\n",
      "        [55, 57, 57, 51,  1, 57, 51,  1]])\n",
      "\n",
      "Tragets :\n",
      "torch.Size([4, 8])\n",
      "tensor([[65,  1, 66, 59,  1, 61, 51, 66],\n",
      "        [55,  1, 47, 57, 57, 79, 63, 51],\n",
      "        [ 0,  0, 31, 57,  1, 48, 47, 55],\n",
      "        [57, 57, 51,  1, 57, 51,  1, 58]])\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size = 4  # how many independent sequences will we process in //\n",
    "block_size = 8  # what ia the maximum context length for predictions\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    x = torch.stack([data[i: i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1: i + block_size + 1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('Inputs :')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('')\n",
    "print('Tragets :')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the input is tensor([55]) the target is: 65\n",
      "When the input is tensor([55, 65]) the target is: 1\n",
      "When the input is tensor([55, 65,  1]) the target is: 66\n",
      "When the input is tensor([55, 65,  1, 66]) the target is: 59\n",
      "When the input is tensor([55, 65,  1, 66, 59]) the target is: 1\n",
      "When the input is tensor([55, 65,  1, 66, 59,  1]) the target is: 61\n",
      "When the input is tensor([55, 65,  1, 66, 59,  1, 61]) the target is: 51\n",
      "When the input is tensor([55, 65,  1, 66, 59,  1, 61, 51]) the target is: 66\n",
      "When the input is tensor([66]) the target is: 55\n",
      "When the input is tensor([66, 55]) the target is: 1\n",
      "When the input is tensor([66, 55,  1]) the target is: 47\n",
      "When the input is tensor([66, 55,  1, 47]) the target is: 57\n",
      "When the input is tensor([66, 55,  1, 47, 57]) the target is: 57\n",
      "When the input is tensor([66, 55,  1, 47, 57, 57]) the target is: 79\n",
      "When the input is tensor([66, 55,  1, 47, 57, 57, 79]) the target is: 63\n",
      "When the input is tensor([66, 55,  1, 47, 57, 57, 79, 63]) the target is: 51\n",
      "When the input is tensor([9]) the target is: 0\n",
      "When the input is tensor([9, 0]) the target is: 0\n",
      "When the input is tensor([9, 0, 0]) the target is: 31\n",
      "When the input is tensor([ 9,  0,  0, 31]) the target is: 57\n",
      "When the input is tensor([ 9,  0,  0, 31, 57]) the target is: 1\n",
      "When the input is tensor([ 9,  0,  0, 31, 57,  1]) the target is: 48\n",
      "When the input is tensor([ 9,  0,  0, 31, 57,  1, 48]) the target is: 47\n",
      "When the input is tensor([ 9,  0,  0, 31, 57,  1, 48, 47]) the target is: 55\n",
      "When the input is tensor([55]) the target is: 57\n",
      "When the input is tensor([55, 57]) the target is: 57\n",
      "When the input is tensor([55, 57, 57]) the target is: 51\n",
      "When the input is tensor([55, 57, 57, 51]) the target is: 1\n",
      "When the input is tensor([55, 57, 57, 51,  1]) the target is: 57\n",
      "When the input is tensor([55, 57, 57, 51,  1, 57]) the target is: 51\n",
      "When the input is tensor([55, 57, 57, 51,  1, 57, 51]) the target is: 1\n",
      "When the input is tensor([55, 57, 57, 51,  1, 57, 51,  1]) the target is: 58\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t + 1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"When the input is {context} the target is: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size) -> None:\n",
    "        super().__init__()\n",
    "        # Each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B, T) tensor of intergers\n",
    "        logits = self.token_embedding_table(idx)  # (B, T, C)\n",
    "        # B => Number of batch\n",
    "        # T => The size of the context\n",
    "        # C => Number od Channel, i.e. the size of the vocabulary\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # For the cross_entropy the channel C must be the second one\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only in the last time step\n",
    "            logits = logits[:, -1, :]\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=1)  # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T + 1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross entropy return a loss for a random choose around $-ln(1/vocab\\_size)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 90])\n",
      "tensor(5.3363, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6xxôjNfN7t)h»mai1PAbv3TÇXzf3JâD3î,«JmIè4èéeTqfBm'0uu5(ppeBçH-ùçt'\n",
      "Caœ1Xêxn?EBJâzI3(F.2O5d.( c(œ9î6MV\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(list(m.generate(idx, max_new_tokens=100)[0].numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of a pytroch optimization object\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [05:48<00:00, 287.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1773054599761963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in tqdm(range(100000)):\n",
    "\n",
    "    # sample batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()  # get the gradients for all parameters\n",
    "    optimizer.step()  # uptdate parameters\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "L'à prèrroù uet t die ut amaprelurilecôti eait, Tu mentex s s à Flouenveit renes plemeairoulaun tôtenc den'ase re gris ene Ile la té, plet s l'e me aueluindet (Peseuenaseuerret le eriana e fe aimaillofie avembrtist qutillaivotreue trgntirbes-jopâprieliqut lsealte Doilleitentre onait pi queude ssouavaie arse ur qusirietr A paispe daireçoiness te ces, tte, l ist desond masountte caitirdés s fulul\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(list(m.generate(idx, max_new_tokens=400)[0].numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid communication bewteen past and the \"future\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first use a very poor meethod to aggregate previous information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want x[b, t] = mean_{i<=t} x_{b, i}\n",
    "# version 1: uggly way\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, : t + 1] # (t, C)\n",
    "        \n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0431, -1.6047],\n",
       "        [ 1.7878, -0.4780],\n",
       "        [-0.2429, -0.9342],\n",
       "        [-0.2483, -1.2082],\n",
       "        [-0.7688,  0.7624],\n",
       "        [-1.5673, -0.2394],\n",
       "        [ 2.3228, -0.9634],\n",
       "        [ 2.0024,  0.4664]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0431, -1.6047],\n",
       "        [ 0.8724, -1.0414],\n",
       "        [ 0.5006, -1.0056],\n",
       "        [ 0.3134, -1.0563],\n",
       "        [ 0.0970, -0.6925],\n",
       "        [-0.1804, -0.6170],\n",
       "        [ 0.1772, -0.6665],\n",
       "        [ 0.4053, -0.5249]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use a better way to aggregate information using // calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "----\n",
      "b =  tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "----\n",
      "c =  tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b  # matrix multiplication\n",
    "print(\"a = \", a)\n",
    "print('----')\n",
    "print(\"b = \", b)\n",
    "print('----')\n",
    "print(\"c = \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: use @\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei /= wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x  # (T, T) * (B, T, C) --> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros(T, T)\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 4: self-attention\n",
    "torch.manual_seed(42)\n",
    "B, T, C = 4, 8, 32  # batch, time, channels\n",
    "x = torch.randn(B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see a single head perform sel-attention\n",
    "# self-attention because k, q and v are all calculated from x\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "querry = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x)  # (B, T, 16)\n",
    "q = querry(x)  # (B, T, 16)\n",
    "wei = q @ k.transpose(-2, -1)  # (B, T, 16) @ (B, 16, T) --> (B, T, T)   # We can  multipy by  * head_size**-0.5 to control the variance\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))  # For sentimental analysis we can comment this mask\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1905, 0.8095, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3742, 0.0568, 0.5690, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1288, 0.3380, 0.1376, 0.3956, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4311, 0.0841, 0.0582, 0.3049, 0.1217, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0537, 0.3205, 0.0694, 0.2404, 0.2568, 0.0592, 0.0000, 0.0000],\n",
       "        [0.3396, 0.0149, 0.5165, 0.0180, 0.0658, 0.0080, 0.0373, 0.0000],\n",
       "        [0.0165, 0.0375, 0.0144, 0.1120, 0.0332, 0.4069, 0.3136, 0.0660]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
